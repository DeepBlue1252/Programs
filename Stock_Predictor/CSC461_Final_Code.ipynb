{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePCnd2O4g0IW"
      },
      "source": [
        "## 461 Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bTwmrlvg5ij"
      },
      "outputs": [],
      "source": [
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9fqfAWtgyps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import datetime\n",
        "\n",
        "# Define the stock symbols\n",
        "stocks = {\n",
        "    'Banking': ['JPM', 'BAC', 'WFC'],\n",
        "    'Communication': ['T', 'VZ', 'CMCSA'],\n",
        "    'Manufacturing': ['GE', 'MMM', 'HON'],\n",
        "    'Technology': ['AAPL', 'MSFT', 'GOOGL']\n",
        "}\n",
        "\n",
        "# Function to fetch historical data\n",
        "\n",
        "# Function to fetch historical data\n",
        "def fetch_data(stocks, start_date, end_date):\n",
        "    historical_data = {}\n",
        "    for sector, symbols in stocks.items():\n",
        "        historical_data[sector] = {symbol: yf.Ticker(symbol).history(start=start_date, end=end_date) for symbol in symbols}\n",
        "    return historical_data\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2023-11-30'\n",
        "\n",
        "# Fetch the data\n",
        "data = fetch_data(stocks, start_date, end_date)\n",
        "\n",
        "# Model Functions\n",
        "def apply_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    return np.sqrt(mean_squared_error(y_test, predictions))\n",
        "\n",
        "def prepare_data(stock_data):\n",
        "    stock_data['Target'] = stock_data['Close'].shift(-1)\n",
        "    stock_data = stock_data.dropna()  # Drop NaN values from the entire dataframe\n",
        "    X = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    y = stock_data['Target']\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def polynomial_regression(X_train, X_test, y_train, y_test, degree):\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_poly, y_train)\n",
        "    predictions = model.predict(X_test_poly)\n",
        "    return np.sqrt(mean_squared_error(y_test, predictions))\n",
        "\n",
        "# Iterate over each sector and stock\n",
        "results = {}\n",
        "for sector, stocks in data.items():\n",
        "    sector_results = {}\n",
        "    for stock_symbol, stock_data in stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Scale Data for Some Models\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Apply Models\n",
        "        stock_results = {\n",
        "            'Linear': apply_model(LinearRegression(), X_train, X_test, y_train, y_test),\n",
        "            'Ridge': apply_model(Ridge(), X_train_scaled, X_test_scaled, y_train, y_test),\n",
        "            'Lasso': apply_model(Lasso(), X_train_scaled, X_test_scaled, y_train, y_test),\n",
        "            'SGD': apply_model(SGDRegressor(), X_train_scaled, X_test_scaled, y_train, y_test),\n",
        "            'DecisionTree': apply_model(DecisionTreeRegressor(), X_train, X_test, y_train, y_test),\n",
        "            'RandomForest': apply_model(RandomForestRegressor(), X_train, X_test, y_train, y_test),\n",
        "            # Add more models as needed\n",
        "        }\n",
        "\n",
        "        # DNN Model\n",
        "        dnn_model = Sequential([Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "                                Dense(64, activation='relu'),\n",
        "                                Dense(32, activation='relu'),\n",
        "                                Dense(1)])\n",
        "        dnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        dnn_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32)\n",
        "        dnn_predictions = dnn_model.predict(X_test_scaled)\n",
        "        stock_results['DNN'] = np.sqrt(mean_squared_error(y_test, dnn_predictions))\n",
        "\n",
        "        sector_results[stock_symbol] = stock_results\n",
        "    results[sector] = sector_results\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, stock_data in sector_data.items():\n",
        "        print(f\"  Stock: {stock}\")\n",
        "        for model, rmse in stock_data.items():\n",
        "            print(f\"    Model: {model}, RMSE: {rmse}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "LCI0mcNUj4oS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkRQvHlvgytY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function for Polynomial Regression\n",
        "def polynomial_regression(X_train, X_test, y_train, y_test, degree):\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_poly, y_train)\n",
        "    predictions = model.predict(X_test_poly)\n",
        "    return np.sqrt(mean_squared_error(y_test, predictions))\n",
        "\n",
        "# Function to prepare data\n",
        "def prepare_data(stock_data):\n",
        "    stock_data['Target'] = stock_data['Close'].shift(-1)\n",
        "    stock_data.dropna(inplace=True)\n",
        "    X = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    y = stock_data['Target']\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Iterate over each sector and stock\n",
        "results = {}\n",
        "for sector, stocks in data.items():\n",
        "    sector_results = {}\n",
        "    for stock_symbol, stock_data in stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Find the best degree for Polynomial Regression\n",
        "        best_degree = None\n",
        "        lowest_rmse = float('inf')\n",
        "        for degree in range(1, 10):  # Test degrees from 1 to 4\n",
        "            rmse = polynomial_regression(X_train, X_test, y_train, y_test, degree)\n",
        "            if rmse < lowest_rmse:\n",
        "                best_degree = degree\n",
        "                lowest_rmse = rmse\n",
        "\n",
        "        sector_results[stock_symbol] = {'Best Degree': best_degree, 'RMSE': lowest_rmse}\n",
        "    results[sector] = sector_results\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, best_data in sector_data.items():\n",
        "        print(f\"  Stock: {stock}, Best Degree: {best_data['Best Degree']}, RMSE: {best_data['RMSE']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8uEWzDjv6T3"
      },
      "outputs": [],
      "source": [
        "stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nckpqvrhgyzb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Define the stock symbols\n",
        "stocks = {\n",
        "    'Banking': ['JPM', 'BAC', 'WFC'],\n",
        "    'Communication': ['T', 'VZ', 'CMCSA'],\n",
        "    'Manufacturing': ['GE', 'MMM', 'HON'],\n",
        "    'Technology': ['AAPL', 'MSFT', 'GOOGL']\n",
        "}\n",
        "\n",
        "# Function to fetch historical data\n",
        "\n",
        "# Function to fetch historical data\n",
        "def fetch_data(stocks, start_date, end_date):\n",
        "    historical_data = {}\n",
        "    for sector, symbols in stocks.items():\n",
        "        historical_data[sector] = {symbol: yf.Ticker(symbol).history(start=start_date, end=end_date) for symbol in symbols}\n",
        "    return historical_data\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2023-11-30'\n",
        "\n",
        "# Fetch the data\n",
        "data = fetch_data(stocks, start_date, end_date)\n",
        "def elasticnet_regression(X_train, X_test, y_train, y_test, alpha=1.0, l1_ratio=0.5):\n",
        "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    return np.sqrt(mean_squared_error(y_test, predictions))\n",
        "\n",
        "elasticnet_details = {}\n",
        "results = {}  # Ensure this dictionary is initialized\n",
        "# ElasticNet with different alpha values\n",
        "for sector, stocks in data.items():\n",
        "    sector_results = {}\n",
        "    for stock_symbol, stock_data in stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Scale Data for Some Models\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # ElasticNet with different alpha values\n",
        "        elasticnet_results = {}\n",
        "        best_alpha = None\n",
        "        lowest_rmse = float('inf')\n",
        "        for alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,15]:\n",
        "            rmse = elasticnet_regression(X_train_scaled, X_test_scaled, y_train, y_test, alpha=alpha)\n",
        "            elasticnet_results[alpha] = rmse\n",
        "            if rmse < lowest_rmse:\n",
        "                best_alpha = alpha\n",
        "                lowest_rmse = rmse\n",
        "        elasticnet_best = {'Best Alpha': best_alpha, 'RMSE': lowest_rmse}\n",
        "        elasticnet_details[stock_symbol] = elasticnet_results\n",
        "\n",
        "        # Combine results\n",
        "        stock_results = {'ElasticNet': elasticnet_best}  # Add other models here as well\n",
        "        sector_results[stock_symbol] = stock_results\n",
        "    results[sector] = sector_results\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, stock_data in sector_data.items():\n",
        "        print(f\"  Stock: {stock}\")\n",
        "        for model, model_data in stock_data.items():\n",
        "            print(f\"    Model: {model}, Best Alpha: {model_data['Best Alpha']}, RMSE: {model_data['RMSE']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWbq-qhgxBJF"
      },
      "source": [
        "## DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vv68NQNgzAh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Fetch data (assuming this function is already defined)\n",
        "def fetch_data(stocks):\n",
        "    historical_data = {}\n",
        "    for sector, symbols in stocks.items():\n",
        "        historical_data[sector] = {symbol: yf.Ticker(symbol).history(period=\"5y\") for symbol in symbols}\n",
        "    return historical_data\n",
        "\n",
        "# Data preparation (assuming this function is already defined)\n",
        "def prepare_data(stock_data):\n",
        "    stock_data['Target'] = stock_data['Close'].shift(-1)\n",
        "    stock_data.dropna(inplace=True)\n",
        "    X = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    y = stock_data['Target']\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# DNN Model Building\n",
        "def build_dnn_model(input_shape, dense_layer_sizes, dropout_rate, reg_rate, learning_rate=0.001, activation='relu'):\n",
        "    model = Sequential()\n",
        "    for i, size in enumerate(dense_layer_sizes):\n",
        "        if i == 0:\n",
        "            model.add(Dense(size, activation=activation, input_shape=(input_shape,), kernel_regularizer=l2(reg_rate)))\n",
        "        else:\n",
        "            model.add(Dense(size, activation=activation, kernel_regularizer=l2(reg_rate)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define the stock symbols\n",
        "stocks = {\n",
        "    'Banking': ['JPM', 'BAC', 'WFC'],\n",
        "    'Communication': ['T', 'VZ', 'CMCSA'],\n",
        "    'Manufacturing': ['GE', 'MMM', 'HON'],\n",
        "    'Technology': ['AAPL', 'MSFT', 'GOOGL']\n",
        "}\n",
        "\n",
        "# Fetch and prepare the data\n",
        "data = fetch_data(stocks)\n",
        "results = {}\n",
        "\n",
        "\n",
        "\n",
        "# Training and Evaluating the Model\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def train_and_evaluate(X_train, y_train, X_test, y_test, input_shape, epochs=100, batch_size=32, n_iter=10, cv=3):\n",
        "    model = KerasRegressor(build_fn=lambda dense_layer_sizes, dropout_rate, reg_rate, learning_rate, activation: build_dnn_model(input_shape, dense_layer_sizes, dropout_rate, reg_rate, learning_rate, activation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    param_dist = {\n",
        "        'dense_layer_sizes': [(128, 64, 32), (64, 32), (128, 64), (256, 128, 64)],\n",
        "        'dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
        "        'reg_rate': [0.001, 0.01, 0.05, 0.1],\n",
        "        'learning_rate': [0.001, 0.0005, 0.0001],\n",
        "        'activation': ['relu', 'tanh']\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=n_iter, cv=cv)\n",
        "    random_search_result = random_search.fit(X_train, y_train)\n",
        "    best_model = random_search_result.best_estimator_.model\n",
        "\n",
        "    # Train the best model fully and get the history\n",
        "    history = best_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.2)\n",
        "\n",
        "    predictions = best_model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "    return rmse, random_search_result.best_params_, history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for sector, sector_stocks in data.items():\n",
        "    for stock_symbol, stock_data in sector_stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Scale the data\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train the model and perform hyperparameter tuning\n",
        "        rmse, best_params = train_and_evaluate(X_train_scaled, y_train, X_test_scaled, y_test, input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "        # Store results\n",
        "        if sector not in results:\n",
        "            results[sector] = {}\n",
        "        results[sector][stock_symbol] = {'RMSE': rmse, 'Best Parameters': best_params}\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, metrics in sector_data.items():\n",
        "        print(f\"  Stock: {stock}, RMSE: {metrics['RMSE']}, Best Parameters: {metrics['Best Parameters']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBqGMUp6ps7F"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_and_accuracy(history, stock_symbol):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{stock_symbol} - Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Check if accuracy is in history\n",
        "    if 'accuracy' in history.history:\n",
        "        # Plot accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'{stock_symbol} - Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "for sector, sector_stocks in data.items():\n",
        "    for stock_symbol, stock_data in sector_stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Scale the data\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train the model and perform hyperparameter tuning\n",
        "        rmse, best_params = train_and_evaluate(X_train_scaled, y_train, X_test_scaled, y_test, input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "        # Store results\n",
        "        if sector not in results:\n",
        "            results[sector] = {}\n",
        "        results[sector][stock_symbol] = {'RMSE': rmse, 'Best Parameters': best_params}\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, metrics in sector_data.items():\n",
        "        print(f\"  Stock: {stock}, RMSE: {metrics['RMSE']}, Best Parameters: {metrics['Best Parameters']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6FSoTwxVXxOv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Function to fetch historical data\n",
        "def fetch_data(stocks, start_date, end_date):\n",
        "    historical_data = {}\n",
        "    for sector, symbols in stocks.items():\n",
        "        historical_data[sector] = {symbol: yf.Ticker(symbol).history(start=start_date, end=end_date) for symbol in symbols}\n",
        "    return historical_data\n",
        "\n",
        "# Data preparation for classification\n",
        "\n",
        "\n",
        "def prepare_data(stock_data):\n",
        "    stock_data['Price_Up'] = (stock_data['Close'] < stock_data['Close'].shift(-1)).astype(int)\n",
        "    stock_data.dropna(inplace=True)\n",
        "    X = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    y = stock_data['Price_Up']\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# DNN Classifier\n",
        "def build_dnn_classifier(input_shape, learning_rate=0.001, units_per_layer=[128, 64, 32]):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units_per_layer[0], activation='relu', input_shape=(input_shape,), kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    for units in units_per_layer[1:]:\n",
        "        model.add(Dense(units, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "    model.add(Dense(2, activation='softmax'))  # Binary classification output\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Fine-tuning DNN\n",
        "def build_and_tune_dnn(X_train, y_train, X_val, y_val):\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "    for units in [(128, 64, 32), (100, 50)]:\n",
        "        for lr in [0.001, 0.0001]:\n",
        "            model = build_dnn_classifier(X_train.shape[1], learning_rate=lr, units_per_layer=units)\n",
        "            model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
        "            accuracy = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_model = model\n",
        "    return best_model\n",
        "\n",
        "# KNN Classifier with Grid Search\n",
        "def build_and_tune_knn(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_neighbors': [3, 5, 7],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['euclidean', 'manhattan']\n",
        "    }\n",
        "    knn = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(knn, param_grid, cv=3)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Decision Tree Classifier with Grid Search\n",
        "def build_and_tune_decision_tree(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    }\n",
        "    tree = DecisionTreeClassifier()\n",
        "    grid_search = GridSearchCV(tree, param_grid, cv=3)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Define the stock symbols\n",
        "stocks = {\n",
        "    'Banking': ['JPM', 'BAC', 'WFC'],\n",
        "    'Communication': ['T', 'VZ', 'CMCSA'],\n",
        "    'Manufacturing': ['GE', 'MMM', 'HON'],\n",
        "    'Technology': ['AAPL', 'MSFT', 'GOOGL']\n",
        "}\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2023-11-30'\n",
        "\n",
        "# Fetch the data\n",
        "data = fetch_data(stocks, start_date, end_date)\n",
        "\n",
        "# Process data and train models\n",
        "results = {}\n",
        "for sector, sector_stocks in data.items():\n",
        "    for stock_symbol, stock_data in sector_stocks.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data(stock_data)\n",
        "\n",
        "        # Scale the data for DNN and KNN\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "        # Splitting a validation set for DNN\n",
        "\n",
        "        # Splitting the data for Decision Tree classifier\n",
        "        X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Decision Tree\n",
        "        tree_model = build_and_tune_decision_tree(X_train_tree, y_train_tree)\n",
        "        tree_accuracy = tree_model.score(X_test_tree, y_test_tree)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # DNN\n",
        "        dnn_model = build_and_tune_dnn(X_train_scaled, y_train, X_val_scaled, y_val)\n",
        "        dnn_predictions = np.argmax(dnn_model.predict(X_test_scaled), axis=-1)\n",
        "        dnn_accuracy = accuracy_score(y_test, dnn_predictions)\n",
        "\n",
        "\n",
        "\n",
        "        # KNN\n",
        "        knn_model = build_and_tune_knn(X_train_scaled, y_train)\n",
        "        knn_accuracy = knn_model.score(X_test_scaled, y_test)\n",
        "\n",
        "        # Decision Tree\n",
        "        tree_model = build_and_tune_decision_tree(X_train_tree, y_train_tree)\n",
        "        tree_accuracy = tree_model.score(X_test_tree, y_test_tree)\n",
        "\n",
        "        # Store results\n",
        "        if sector not in results:\n",
        "            results[sector] = {}\n",
        "        results[sector][stock_symbol] = {\n",
        "            'DNN Accuracy': dnn_accuracy,\n",
        "            'KNN Accuracy': knn_accuracy,\n",
        "            'Decision Tree Accuracy': tree_accuracy\n",
        "        }\n",
        "\n",
        "# Display results\n",
        "for sector, sector_data in results.items():\n",
        "    print(f\"Sector: {sector}\")\n",
        "    for stock, accuracies in sector_data.items():\n",
        "        print(f\"  Stock: {stock}, Accuracies: {accuracies}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}